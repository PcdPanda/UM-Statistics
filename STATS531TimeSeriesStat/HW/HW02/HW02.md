# STATS531 HW2

Author: Chongdan Pan(pandapcd)

### Question 2.1(A)

1. Based on the definition of ACF $\gamma_h$
   $$
   \gamma_h=\text{Cov}(X_n, X_{n+h})=\text{Cov}(X_n, \phi X_{n+h-1}+\epsilon_{n+h})=\phi\text{Cov}(X_n, X_{n+h-1})+\text{Cov}(X_n,\epsilon_{n+h})
   $$

2. Since there is no correlation between $\epsilon$ and $X_n$, we can delete it, and form a recursive equation
   $$
   \gamma_h=\phi\gamma_{h-1}=\phi^k\gamma_{h-k}
   $$

3. Let $k=h$, we have
   $$
   \gamma_h=\phi^h\gamma_0
   $$

4. For $\gamma_0$, we have
   $$
   \gamma_0=\text{Var}(X_n)=\text{Var}(X_{n-1})=\phi^2\text{Var}(X_{n-1})+\text{Var}(\epsilon)
   $$

5. Therefore, we have 

   $A=\gamma_0=\frac{\sigma^2}{1-\phi^2}$

6. Since $\lambda=\phi$, the final result is 
   $$
   \gamma_h=\frac{\phi^h}{1-\phi^2}\sigma^2
   $$
   



### Question 2.1(B)

1. By subtracting $\phi X_{n-1}$ from both sides of the equation, we have the MA($\infty$) representation
   $$
   X_n-\phi X_{n-1}=\epsilon_n\rightarrow X_n=(1-B\phi)^{-1}\epsilon_n
   $$

2. Then we can have the Taylor series expansion for $g(x)=(1-\phi x)^{-1}$
   $$
   g(x)=\sum_{j=0}^\infty \frac{\mathrm d^jg(x)}{\mathrm dx^j}|_{x=0}\frac{x^j}{j!}
   $$

3. The derivative can be computed recursively as 
   $$
   \frac{\mathrm dg(x)}{\mathrm dx}=\phi(1-\phi x)^{-2}\rightarrow \frac{\mathrm d^jg(x)}{\mathrm dx^j}=j!\phi^j(1-\phi x)^{-j-1}
   $$
   
4. Therefore, we can apply the Taylor expansion with the operator $B$
   $$
   g(B)=\sum_{j=0}^\infty \phi^jB^j\rightarrow X_n=\sum_{j=0}^\infty \phi^j\epsilon_{n-j}
   $$

5. 

5. For MA $(\infty)$ auto covariance, we have 
   $$
   \gamma_h=\sum_{j=0}^\infty g_jg_{j+h}\sigma^2=\sigma^2\sum_{j=0}^\infty g_jg_{j+h}\quad\text{where}\quad g_j=\phi^j
   $$

6. Therefore, we have the result
   $$
   \gamma_h=\sigma^2\phi^h\sum_{j=0}^\infty \phi^{2j}=\frac{\phi^h}{1-\phi^2}\sigma^2
   $$

### Question 2.1(C)

Based on our calculation of auto covariance, the auto correlation is 
$$
\rho_h=\frac{\gamma_h}{\gamma_0}=\phi^h
$$
The result from RStudio, which is extremely close to my computation

```R
phi <- 0.8
N <- 100
X <- numeric(N)
for(n in 1:N)X[n] <- phi ^ (n-1)
acf <- ARMAacf(ar=0.8, lag.max=N-1)
max(acf - X)
# 5.551115e-17
```

![ACF](H:\UMSI\UM-Statistics\STATS531TimeSeriesStat\HW\HW02\ACF.png)

### Question 2.2

1. Assume $n=m+h$, then based on the definition of $\text{Cov}(X_m, X_{m+h})$, we have
   $$
   \gamma_h=\text{Cov}(X_m, X_{m+h})=\text{Cov}(X_m, X_{m+h-1}+\epsilon_{m+h})
   $$

2. Since $\epsilon$ is i.i.d, we have
   $$
   \gamma_{mn}=\gamma_h=\text{Cov}(X_m, X_{m+h-1})=\text{Cov}(X_m, X_{m})
   $$

3. Based on the result of $X_m$
   $$
   \gamma_{mn}=\text{Cov}(\sum_{i=1}^m\epsilon_i,\sum_{i=1}^m\epsilon_i)=\sum_{i=1}^m\text{Var}(\epsilon_i)=m\sigma^2
   $$
   
4. Similarly, if $m=n+h$, we have
   $$
   \gamma_{mn}=n\sigma^2
   $$

4. Therefore, the result is 
   $$
   \gamma_{mn}=\min(m,n)\sigma^2
   $$
   

### Question 2.3

I've two participation records at Piazza this week.

1. [Discuss the question related to burn-in](https://piazza.com/class/kxjb75njby03j5?cid=27)
2. [Post a question related the sinusoidal solution to the oscillate equation](https://piazza.com/class/kxjb75njby03j5?cid=33)

### Reference

- [Taylor series - Wikipedia](https://en.wikipedia.org/wiki/Taylor_series)
- [The lecture slides for chapter 3](https://ionides.github.io/531w22/03/slides.pdf)

- [The lecture slides for chapter 4](https://ionides.github.io/531w22/04/slides.pdf)
